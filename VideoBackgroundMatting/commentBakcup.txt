(1)
    //Mat cv_frame;
    //读取下一帧
    //double rate = capture.get(CAP_PROP_FPS);
    //double nowframe=capture.get(CAP_PROP_POS_FRAMES );
    //int nows=nowframe/rate;
    //cout<<"nows:"<<nows<<endl;
    //long totalFrameNumber = capture.get(CAP_PROP_FRAME_COUNT);
    //int totals=totalFrameNumber/rate;
    //cout<<"totals:"<<totals<<endl;
    //ui->label_12->setText(stom(nows)+"/"+stom(totals));
(1)

    //string str = string(video_path.toLocal8Bit());
    //in_file = (char*)str.c_str();

(2)
//         //注册所有文件格式
    avdevice_register_all();
    //ffmpeg 解码转码视频
    int i = 0;
    int ret = 0;
    AVFormatContext* fmt_ctx = NULL;
    AVCodecContext* dec_ctx = NULL;
    AVCodec* dec = NULL;

    //分配一个avformat
    fmt_ctx = avformat_alloc_context();
    if (fmt_ctx == NULL)
    {
        QMessageBox::warning(nullptr, "提示", "打开视频失败！fmt_ctx分配错误",
            QMessageBox::Yes | QMessageBox::Yes);
        exit(1);
    }

    //打开文件，解封装
    if (avformat_open_input(&fmt_ctx, in_file, NULL, NULL) != 0)
    {
        //printf("%s", in_file);
        QMessageBox::warning(nullptr, "提示", "打开视频失败！打开文件解封装错误",
            QMessageBox::Yes | QMessageBox::Yes);

        exit(1);
    }

    //查找文件的相关流信息
    if (avformat_find_stream_info(fmt_ctx, NULL) < 0)
    {
        //printf("find stream fail");
        QMessageBox::warning(nullptr, "提示", "打开视频失败！查找文件的相关流信息错误",
            QMessageBox::Yes | QMessageBox::Yes);

        exit(1);
    }

    //输出格式信息
    av_dump_format(fmt_ctx, 0, in_file, 0);

    //查找解码信息
    int stream_index = -1;
    for (i = 0; i < fmt_ctx->nb_streams; i++)
        if (fmt_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
            stream_index = i;
            break;
        }

    if (stream_index == -1)
        printf("find stream fail");

    //保存解码器
    dec = (AVCodec*)avcodec_find_decoder(fmt_ctx->streams[stream_index]->codecpar->codec_id);
    if (dec == NULL)
        printf("find codec fail");

    /* create decoding context 保存解码后数据*/
    dec_ctx = avcodec_alloc_context3(dec);
    if (!dec_ctx)
        printf("avcodec_alloc_context3 failed\n");
    avcodec_parameters_to_context(dec_ctx, fmt_ctx->streams[stream_index]->codecpar);

    if (avcodec_open2(dec_ctx, dec, NULL) < 0)
        printf("can't open codec");


    //创建packet,用于存储解码前的数据
    AVPacket* packet = av_packet_alloc();;
    av_init_packet(packet);

    //设置转码后输出相关参数(AUDIO)

    //创建Frame，用于存储解码后的数据
    AVFrame* frame = av_frame_alloc();

    int buffer_size = av_image_get_buffer_size(AV_PIX_FMT_RGB24, dec_ctx->width, dec_ctx->height, 1);

    //注意要用av_malloc
    uint8_t* buffer = (uint8_t*)av_malloc(sizeof(uint8_t) * buffer_size);

    av_image_fill_arrays(frame->data, frame->linesize, buffer, AV_PIX_FMT_RGB24, dec_ctx->width, dec_ctx->height, 1);

    //打开转码器
    struct SwsContext* convert_ctx = sws_alloc_context();
    //设置转码参数
    convert_ctx = sws_getContext(dec_ctx->width, dec_ctx->height,
        dec_ctx->pix_fmt,
        dec_ctx->width, dec_ctx->height, AV_PIX_FMT_RGB32,
        SWS_BICUBIC, NULL, NULL, NULL);

    //初始化转码器

    //sws_init_context(convert_ctx);
    //while循环，每次读取一帧，并转码

    while (av_read_frame(fmt_ctx, packet) >= 0) {

        if (packet->stream_index == stream_index) {

            //QMessageBox::warning(nullptr, "提示", QString::number(stream_index),
            //                                                                    QMessageBox::Yes | QMessageBox::Yes);
            ret = avcodec_send_packet(dec_ctx, packet);
            //avcodec_send_frame();

            if (ret < 0) {
                fprintf(stderr, "Error sending a packet for decoding\n");
                QMessageBox::warning(nullptr, "提示", "Error sending a packet for decoding",
                    QMessageBox::Yes | QMessageBox::Yes);

                break;
            }

            while (ret >= 0) {
                ret = avcodec_receive_frame(dec_ctx, frame);
                if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
                    break;
                else if (ret < 0) {
                    fprintf(stderr, "Error during decoding\n");
                    break;
                }
                fflush(stdout);
                cv_frame = Avframe2cvMat(frame, dec_ctx->width, dec_ctx->height);
                //QMessageBox::warning(nullptr, "提示", "正在 转化 AVFrame to Qimage",
                                                      //QMessageBox::Yes | QMessageBox::Yes);
                //ui->label_11->setScaledContents(true);

                //视频处理
                if (!capture.read(cv_frame))
                {
                    //ui->textEdit->append(QString::fromLocal8Bit("fail to load video"));
                    return;
                }

                if (type == 1) {
                    //image=gray2(image);
                    cvtColor(cv_frame, cv_frame, CV_BGR2GRAY);
                }
                else if (type == 2) {
                    cvtColor(cv_frame, cv_frame, CV_BGR2GRAY);
                    //高斯滤波
                    GaussianBlur(cv_frame, cv_frame, Size(3, 3),
                        0, 0, BORDER_DEFAULT);
                    //Canny检测
                    int edgeThresh = 100;
                    Mat Canny_result;
                    Canny(cv_frame, cv_frame, edgeThresh, edgeThresh * 3, 3);
                }
                else if (type == 3)
                {
                    //Smooth(frame, frame,Size(3, 3), 0, 0);
                    GaussianBlur(cv_frame, cv_frame, Size(3, 3), 0, 0);
                }
                else if (type == 4) {
                    cvtColor(cv_frame, cv_frame, CV_BGR2GRAY);
                    threshold(cv_frame, cv_frame, 96, 255, THRESH_BINARY);
                }
                else if (type == 5) {
                    cv_frame = masaike(cv_frame);
                }
                //opencv: Mat转Qimage
                QImage image = MatToQImage(cv_frame);

                //绘制到指定位置
                ui->label_11->setScaledContents(true);
                double scale = ui->horizontalSlider_suofang->value() / 100.0;

                QSize qs = ui->label_11->rect().size() * scale;
                ui->label_11->setPixmap(QPixmap::fromImage(image).scaled(qs));
                ui->label_11->setAlignment(Qt::AlignCenter);
                ui->label_11->repaint();
                //=====================================进度位置(通过caputure)
                long totalFrameNumber = capture.get(CAP_PROP_FRAME_COUNT);
                ui->VideohorizontalSlider_2->setMaximum(totalFrameNumber);
                long frameNow = capture.get(CAP_PROP_POS_FRAMES);
                ui->VideohorizontalSlider_2->setValue(frameNow);
                //======================================lable_l2播放时间显示
                double rate = capture.get(CAP_PROP_FPS);
                //double nowframe = capture.get(CAP_PROP_POS_FRAMES);
                int nows = frameNow / rate;
                cout << "nows:" << nows << endl;
                //long totalFrameNumber = capture.get(CAP_PROP_FRAME_COUNT);
                int totals = totalFrameNumber / rate;
                cout << "totals:" << totals << endl;
                ui->label_12->setText(stom(nows) + "/" + stom(totals));
                //======================================

            }
            //QMessageBox::warning(nullptr, "提示", "显示一帧",
            //                                                QMessageBox::Yes | QMessageBox::Yes);

        }
        //release resource
        av_packet_unref(packet);
    }

    //释放转码结构体
    sws_freeContext(convert_ctx);
    //
    av_frame_free(&frame);

    //关闭解码器
    avcodec_close(dec_ctx);
(2)


(3)
    //视频处理
    //if (!capture.read(cv_frame))
    //{
    //    //ui->textEdit->append(QString::fromLocal8Bit("fail to load video"));
    //    return;
    //}

    //if(type==1){
    //    //image=gray2(image);
    //    cvtColor(cv_frame,cv_frame,CV_BGR2GRAY);
    //}
    //else if(type==2){
    //    cvtColor(cv_frame, cv_frame, CV_BGR2GRAY);
    //        //高斯滤波
    //        GaussianBlur(cv_frame, cv_frame, Size(3, 3),
    //            0, 0, BORDER_DEFAULT);
    //        //Canny检测
    //        int edgeThresh =100;
    //        Mat Canny_result;
    //        Canny(cv_frame, cv_frame, edgeThresh, edgeThresh * 3, 3);
    //}else if(type==3)
    //{
    //     //Smooth(frame, frame,Size(3, 3), 0, 0);
         //GaussianBlur(cv_frame, cv_frame, Size(3, 3), 0, 0);
    //}
    //else if(type==4){
    //    cvtColor(cv_frame,cv_frame,CV_BGR2GRAY);
    //    threshold(cv_frame, cv_frame, 96, 255, THRESH_BINARY);
    //}else if (type==5) {
    //    cv_frame=masaike(cv_frame);
    //}


    //opencv: Mat转Qimage 
    //QImage image=MatToQImage(cv_frame);

    //ui->label_11->setScaledContents(true);
    //double scale=ui->horizontalSlider_suofang->value()/100.0;

    //QSize qs = ui->label_11->rect().size()*scale;
    //ui->label_11->setPixmap(QPixmap::fromImage(image).scaled(qs));
    //ui->label_11->setAlignment(Qt::AlignCenter);
    //ui->label_11->repaint();


    //这里加滤波程序

    //long totalFrameNumber = capture.get(CAP_PROP_POS_FRAMES);

   // ui->textEdit->append(QString::fromLocal8Bit("正在读取第：第 %1 帧").arg(totalFrameNumber));
(3)

(4)
    string str = string(video_path.toLocal8Bit());
    in_file = (char*)calloc(1000, sizeof(char));
    in_file = (char*)str.c_str();                   //QString 转为 char*
(4)

(5)
   if (w <= 0) w = avframe->width;
    if (h <= 0) h = avframe->height;
    struct SwsContext* sws_ctx = NULL;
    sws_ctx = sws_getContext(avframe->width, avframe->height, (enum AVPixelFormat)avframe->format,
        w, h, AV_PIX_FMT_BGR24, SWS_BICUBIC, NULL, NULL, NULL);

    Mat mat;
    mat.create(cv::Size(w, h), CV_8UC3);
    AVFrame* bgr24frame = av_frame_alloc();
    bgr24frame->data[0] = (uint8_t*)mat.data;

    int buffer_size = av_image_get_buffer_size(AV_PIX_FMT_RGB24, w, h, 1);

    //注意要用av_malloc
    uint8_t* buffer = (uint8_t*)av_malloc(sizeof(uint8_t) * buffer_size);

    av_image_fill_arrays(bgr24frame->data, bgr24frame->linesize, buffer, AV_PIX_FMT_RGB24, w, h, 1);


    //avpicture_fill((AVPicture*)bgr24frame, bgr24frame->data[0], AV_PIX_FMT_BGR24, w, h);
    sws_scale(sws_ctx,
        (const uint8_t* const*)avframe->data, avframe->linesize,
        0, avframe->height, // from cols=0,all rows trans
        bgr24frame->data, bgr24frame->linesize);

    av_free(bgr24frame);
    sws_freeContext(sws_ctx);
    return mat;
    return Mat();
(5)

(6)
	if (w <= 0) w = avframe->width;
	if (h <= 0) h = avframe->height;
	struct SwsContext* sws_ctx = NULL;
	sws_ctx = sws_getContext(avframe->width, avframe->height, (enum AVPixelFormat)avframe->format,
		w, h, AV_PIX_FMT_BGR24, SWS_BICUBIC, NULL, NULL, NULL);

	cv::Mat mat;
	mat.create(cv::Size(w, h), CV_8UC3);
	AVFrame* bgr24frame = av_frame_alloc();
	bgr24frame->data[0] = (uint8_t*)mat.data;

	int buffer_size = av_image_get_buffer_size(AV_PIX_FMT_RGB24, w, h, 1);

	//注意要用av_malloc
	uint8_t* buffer = (uint8_t*)av_malloc(sizeof(uint8_t) * buffer_size);

	av_image_fill_arrays(bgr24frame->data, bgr24frame->linesize, buffer, AV_PIX_FMT_RGB24, w, h, 1);


	//avpicture_fill((AVPicture*)bgr24frame, bgr24frame->data[0], AV_PIX_FMT_BGR24, w, h);
	sws_scale(sws_ctx,
		(const uint8_t* const*)avframe->data, avframe->linesize,
		0, avframe->height, // from cols=0,all rows trans
		bgr24frame->data, bgr24frame->linesize);

	av_free(bgr24frame);
	sws_freeContext(sws_ctx);
	return mat;
	return cv::Mat();
(6)